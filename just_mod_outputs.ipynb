{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "839420e1",
   "metadata": {},
   "source": [
    "# Gender representation in movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11050952",
   "metadata": {},
   "source": [
    "### Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ba239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pkgs\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn' # to adress problem with chian assignment .loc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f98d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data Viz Pkgs \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e752a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text mining and clening\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a26e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word embedding\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e595535",
   "metadata": {},
   "source": [
    "## 4. Word Embedding with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b89bb",
   "metadata": {},
   "source": [
    "+ 4.1 training a base gender mixed model\n",
    "+ 4.2 training two gender specialized models: \"leia\" trained on female lines and \"luke\" trained on male lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ed358b",
   "metadata": {},
   "source": [
    "### 4.1 base model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4801f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/cleaned_df_for_we.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e702a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = df['dialogue'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcd12864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b829aee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251438"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2180e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [[x for x in word_tokenize(t)] for t in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8984029",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=tokens, vector_size=100, \n",
    "                 window=6, epochs=20, min_count=1, workers=1, seed=1, hashfxn=hash) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ae0171b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shine', 0.6823630928993225),\n",
       " ('sky', 0.6821581721305847),\n",
       " ('sea', 0.6738990545272827),\n",
       " ('mountains', 0.6375836133956909),\n",
       " ('darkness', 0.63669753074646),\n",
       " ('clouds', 0.6235483288764954),\n",
       " ('light', 0.6200230717658997),\n",
       " ('skies', 0.616614818572998),\n",
       " ('shining', 0.6165241003036499),\n",
       " ('wind', 0.6018227338790894)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('sun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53582609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6200231"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('sun', 'light')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7469ede5",
   "metadata": {},
   "source": [
    "### 4.2  Training two gender specialized models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7abff74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_f = df[df['gender'] == 'F']['dialogue'].tolist()\n",
    "lines_m = df[df['gender'] == 'M']['dialogue'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac8ad87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71809"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12f4e78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179629"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea698417",
   "metadata": {},
   "source": [
    "**Training specialized model on female lines, named \"leia\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1a5e2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_f = [[x for x in word_tokenize(t)] for t in lines_f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3a410b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "leia = Word2Vec(sentences=tokens_f, vector_size=100, \n",
    "                 window=6, epochs=20, min_count=1, workers=1, seed=1, hashfxn=hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ca6727f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shine', 0.8102126717567444),\n",
       " ('desert', 0.798184871673584),\n",
       " ('reservation', 0.7832241654396057),\n",
       " ('shines', 0.7584901452064514),\n",
       " ('conjuction', 0.7490602731704712),\n",
       " ('mansion', 0.7439008355140686),\n",
       " ('erik', 0.742368757724762),\n",
       " ('squalid', 0.7353989481925964),\n",
       " ('legs', 0.7325146198272705),\n",
       " ('tent', 0.7321624755859375)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('sun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "17248bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61100084"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similarity('sun', 'light')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c6166d",
   "metadata": {},
   "source": [
    "**Training a specialized model on male lines, named luke**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8b6f52af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_m = [[x for x in word_tokenize(t)] for t in lines_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "959dca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "luke = Word2Vec(sentences=tokens_m, vector_size=100, \n",
    "                 window=6, epochs=20, min_count=1, workers=1, seed=1, hashfxn=hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ffcf6ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wind', 0.6716731190681458),\n",
       " ('sky', 0.6704768538475037),\n",
       " ('tower', 0.6629658937454224),\n",
       " ('beneath', 0.6577014327049255),\n",
       " ('darkness', 0.6553227305412292),\n",
       " ('sea', 0.6548003554344177),\n",
       " ('clouds', 0.6481729745864868),\n",
       " ('stained', 0.6376938223838806),\n",
       " ('winter', 0.6260844469070435),\n",
       " ('tide', 0.6188468337059021)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('sun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2680a11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.608419"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similarity('sun', 'light')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c0d154",
   "metadata": {},
   "source": [
    "## 5  Using leia e luke models to compare the semantic shift of words related to agentinc and communal contents\n",
    "+ 5.1 Usign leia and luke to compare the semantic shift of words related to agentinc and communal contents\n",
    "    + 5.1.1 Exploring semantic contex of words related to agentic content\n",
    "    + 5.1.2 Exploring semantic contex of words related to communal content\n",
    "    + 5.1.3 Exploring semantic contex of other related words\n",
    "    + 5.1.4 Using the specialized models to compare the shift of specific words relations\n",
    "    + 5.1.5 Using the specialized models to compare the shift of specific words analogies among words\n",
    "    + 5.1.6 Using the specialized models to compare the shift on semantic mean among words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55059194",
   "metadata": {},
   "source": [
    "#### 5.1.1 Exploring semantic contex of words related to Agentic content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c550a",
   "metadata": {},
   "source": [
    "**DECISION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6879d3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decisions', 0.7197191715240479),\n",
       " ('arrangements', 0.6749248504638672),\n",
       " ('exception', 0.6729210615158081),\n",
       " ('mistakes', 0.6341828107833862),\n",
       " ('smarted', 0.6293575763702393),\n",
       " ('recalcitrant', 0.6244298815727234),\n",
       " ('statement', 0.6187847852706909),\n",
       " ('proposition', 0.6170982718467712),\n",
       " ('sideration', 0.6155766248703003),\n",
       " ('threats', 0.6050094366073608)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('decision') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a8e4a7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decisions', 0.8534195423126221),\n",
       " ('creations', 0.850827157497406),\n",
       " ('mistakes', 0.823603630065918),\n",
       " ('bergdorf', 0.8183647394180298),\n",
       " ('arrangements', 0.8180564641952515),\n",
       " ('uncomfortable', 0.8167127966880798),\n",
       " ('sacrifice', 0.8145965337753296),\n",
       " ('cinnamon', 0.8086382746696472),\n",
       " ('excuses', 0.8074338436126709),\n",
       " ('bigs', 0.8051620721817017)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('decision') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e866c5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decisions', 0.7834005355834961),\n",
       " ('exception', 0.7350913882255554),\n",
       " ('mistakes', 0.7244989275932312),\n",
       " ('sideration', 0.7123640179634094),\n",
       " ('accusations', 0.6942721009254456),\n",
       " ('arrangements', 0.6778229475021362),\n",
       " ('inquiries', 0.6738249659538269),\n",
       " ('statement', 0.6631120443344116),\n",
       " ('judgments', 0.6504478454589844),\n",
       " ('hhhh', 0.6475404500961304)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('decision') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59a1045",
   "metadata": {},
   "source": [
    "**Leader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e110f350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rosette', 0.6524062156677246),\n",
       " ('litigator', 0.6373560428619385),\n",
       " ('macmillan', 0.6284849643707275),\n",
       " ('nation', 0.6247855424880981),\n",
       " ('drama', 0.6210361123085022),\n",
       " ('warrior', 0.6155075430870056),\n",
       " ('guatemala', 0.6148567199707031),\n",
       " ('anatomy', 0.6135656833648682),\n",
       " ('ent', 0.60845547914505),\n",
       " ('togetherness', 0.6074639558792114)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('leader') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3c71e144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('corporal', 0.9399076700210571),\n",
       " ('vu', 0.9337121844291687),\n",
       " ('hallucinations', 0.9309984445571899),\n",
       " ('monroe', 0.9283525943756104),\n",
       " ('sooze', 0.9274176359176636),\n",
       " ('stratford', 0.9270815849304199),\n",
       " ('cor', 0.9266927242279053),\n",
       " ('seating', 0.9266908764839172),\n",
       " ('danke', 0.9254482984542847),\n",
       " ('groomsmen', 0.9253164529800415)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('leader') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ccbb13f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('litigator', 0.7071031928062439),\n",
       " ('dan', 0.7053254246711731),\n",
       " ('refutes', 0.699674665927887),\n",
       " ('craps', 0.6988564133644104),\n",
       " ('nicollet', 0.6927452087402344),\n",
       " ('quelled', 0.6779463887214661),\n",
       " ('assures', 0.6739602088928223),\n",
       " ('flaky', 0.6711775064468384),\n",
       " ('warrior', 0.669185996055603),\n",
       " ('discovery', 0.6669968366622925)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('leader') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16067e09",
   "metadata": {},
   "source": [
    "**GAME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7c1ce0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('poker', 0.6414844393730164),\n",
       " ('games', 0.6213323473930359),\n",
       " ('ball', 0.6108510494232178),\n",
       " ('playing', 0.5868260264396667),\n",
       " ('score', 0.5813661217689514),\n",
       " ('football', 0.5682152509689331),\n",
       " ('player', 0.5583169460296631),\n",
       " ('baseball', 0.5533324480056763),\n",
       " ('league', 0.5341354012489319),\n",
       " ('play', 0.525000810623169)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e0a6cbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('play', 0.6818333864212036),\n",
       " ('semester', 0.6667368412017822),\n",
       " ('date', 0.6659095287322998),\n",
       " ('fallbrooks', 0.6656503081321716),\n",
       " ('blankets', 0.6652902364730835),\n",
       " ('line', 0.6646506786346436),\n",
       " ('teams', 0.6621901392936707),\n",
       " ('playing', 0.659890353679657),\n",
       " ('krikorian', 0.6578359007835388),\n",
       " ('option', 0.656433641910553)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('game') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e771126d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('poker', 0.6576982140541077),\n",
       " ('games', 0.6526516675949097),\n",
       " ('ball', 0.6479764580726624),\n",
       " ('player', 0.6122198104858398),\n",
       " ('playing', 0.609562337398529),\n",
       " ('football', 0.5922623872756958),\n",
       " ('score', 0.5821939706802368),\n",
       " ('league', 0.5638052821159363),\n",
       " ('baseball', 0.5617274045944214),\n",
       " ('lotto', 0.5580083131790161)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('game') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdde0f6",
   "metadata": {},
   "source": [
    "**LAW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4314029d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enforcement', 0.746232807636261),\n",
       " ('interning', 0.6517430543899536),\n",
       " ('reiser', 0.6142669916152954),\n",
       " ('entrepreneurial', 0.577978253364563),\n",
       " ('constraint', 0.5661510229110718),\n",
       " ('expel', 0.5633748769760132),\n",
       " ('certificate', 0.5573444962501526),\n",
       " ('hotpants', 0.5473726987838745),\n",
       " ('anthology', 0.5393033623695374),\n",
       " ('university', 0.5392829179763794)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('law') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fb7c1442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vigil', 0.8652543425559998),\n",
       " ('concubine', 0.8334420323371887),\n",
       " ('teaching', 0.8287087082862854),\n",
       " ('dropout', 0.8170924782752991),\n",
       " ('seniors', 0.811064600944519),\n",
       " ('accredited', 0.8077389001846313),\n",
       " ('ballard', 0.8058022856712341),\n",
       " ('ban', 0.8047893047332764),\n",
       " ('warner', 0.8044354915618896),\n",
       " ('bazaar', 0.8042718768119812)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('law') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dad76386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enforcement', 0.7834931015968323),\n",
       " ('federal', 0.6550663113594055),\n",
       " ('interning', 0.6106180548667908),\n",
       " ('constraint', 0.6101337671279907),\n",
       " ('government', 0.602654218673706),\n",
       " ('state', 0.6001567840576172),\n",
       " ('official', 0.5880590081214905),\n",
       " ('exec', 0.5687916278839111),\n",
       " ('legal', 0.5635747909545898),\n",
       " ('jurisdiction', 0.562277615070343)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('law') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4350e354",
   "metadata": {},
   "source": [
    "**SPEAK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3255e823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spoken', 0.6269329190254211),\n",
       " ('english', 0.5304036736488342),\n",
       " ('speaks', 0.5252873301506042),\n",
       " ('gaelic', 0.4989660382270813),\n",
       " ('behaving', 0.4964793622493744),\n",
       " ('freely', 0.4896061420440674),\n",
       " ('kulok', 0.48512184619903564),\n",
       " ('interfere', 0.4837225675582886),\n",
       " ('repeat', 0.4822203516960144),\n",
       " ('chose', 0.4816245436668396)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('speak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4476f9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('attorney', 0.7715575695037842),\n",
       " ('thy', 0.7479707598686218),\n",
       " ('thou', 0.7469649910926819),\n",
       " ('shermin', 0.7328740954399109),\n",
       " ('fain', 0.7295507192611694),\n",
       " ('english', 0.7179030179977417),\n",
       " ('democracy', 0.7177442312240601),\n",
       " ('hadst', 0.7149208784103394),\n",
       " ('hast', 0.7105555534362793),\n",
       " ('honesty', 0.7083015441894531)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('speak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9e6c3bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', 0.5766578316688538),\n",
       " ('spoken', 0.5516214966773987),\n",
       " ('deny', 0.537286102771759),\n",
       " ('gaelic', 0.532784640789032),\n",
       " ('speaking', 0.5306099653244019),\n",
       " ('adopt', 0.517009973526001),\n",
       " ('mackelway', 0.5117287635803223),\n",
       " ('adequately', 0.5084408521652222),\n",
       " ('envoys', 0.5082011222839355),\n",
       " ('interfere', 0.5051628351211548)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('speak')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade6fb55",
   "metadata": {},
   "source": [
    "**POLITICS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a7c9f7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('based', 0.6811329126358032),\n",
       " ('art', 0.6494126915931702),\n",
       " ('sexual', 0.6125303506851196),\n",
       " ('experiences', 0.6120377779006958),\n",
       " ('legal', 0.6115383505821228),\n",
       " ('scientific', 0.6066733002662659),\n",
       " ('culture', 0.594924807548523),\n",
       " ('interfere', 0.5910207033157349),\n",
       " ('science', 0.589777946472168),\n",
       " ('religious', 0.5882869958877563)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('politics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7d4b0eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('defense', 0.9306066632270813),\n",
       " ('incomprehensible', 0.9229183197021484),\n",
       " ('heartbreak', 0.9215785264968872),\n",
       " ('abolishment', 0.9208872318267822),\n",
       " ('quad', 0.9208745956420898),\n",
       " ('interpretation', 0.9186541438102722),\n",
       " ('sleaziest', 0.9181327223777771),\n",
       " ('apartheid', 0.9145314693450928),\n",
       " ('regulatory', 0.9140927195549011),\n",
       " ('tapestry', 0.9137299656867981)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('politics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cb88702a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('subconscious', 0.6729413866996765),\n",
       " ('cynical', 0.6536476016044617),\n",
       " ('inclined', 0.6310921907424927),\n",
       " ('common', 0.6258177757263184),\n",
       " ('loosely', 0.6250626444816589),\n",
       " ('cruel', 0.6238190531730652),\n",
       " ('lack', 0.6216678619384766),\n",
       " ('ordinary', 0.6212913990020752),\n",
       " ('unfair', 0.6207675933837891),\n",
       " ('freedom', 0.6126900315284729)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('politics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab793262",
   "metadata": {},
   "source": [
    "**ECONOMICS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "190eb93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('phuket', 0.7519070506095886),\n",
       " ('eater', 0.7387711405754089),\n",
       " ('physicists', 0.7374659180641174),\n",
       " ('ch√©rie', 0.7322070002555847),\n",
       " ('apoc', 0.7310646176338196),\n",
       " ('brahms', 0.7237496972084045),\n",
       " ('commend', 0.720696210861206),\n",
       " ('capillary', 0.7202239036560059),\n",
       " ('reminders', 0.7195419669151306),\n",
       " ('dominique', 0.7190027236938477)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('economics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e48928",
   "metadata": {},
   "source": [
    "leia.wv.similar_by_word('economics') # here she returns KeyError: \"Key 'economics' not present\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9e48878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('colleen', 0.795127809047699),\n",
       " ('contingencies', 0.7926405668258667),\n",
       " ('appipulai', 0.7925943732261658),\n",
       " ('lactose', 0.786105215549469),\n",
       " ('germ', 0.785918116569519),\n",
       " ('offerin', 0.7847583889961243),\n",
       " ('wannabee', 0.7806900143623352),\n",
       " ('pence', 0.7805798053741455),\n",
       " ('aaaank', 0.7787984609603882),\n",
       " ('croupier', 0.7769577503204346)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('economics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9775eb2",
   "metadata": {},
   "source": [
    "#### 5.1.2 Exploring semantic contex of words related to communal content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d6b635",
   "metadata": {},
   "source": [
    "**TRUST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "91443304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trusted', 0.5230218768119812),\n",
       " ('faith', 0.49484074115753174),\n",
       " ('choose', 0.46691998839378357),\n",
       " ('honest', 0.4587436616420746),\n",
       " ('helped', 0.4499565064907074),\n",
       " ('personal', 0.44284331798553467),\n",
       " ('implicitly', 0.441128671169281),\n",
       " ('ancients', 0.44054579734802246),\n",
       " ('respect', 0.438378244638443),\n",
       " ('willing', 0.433566689491272)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('trust') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e6289b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('implicitly', 0.7619571089744568),\n",
       " ('ballplayer', 0.7313967347145081),\n",
       " ('simply', 0.7307876348495483),\n",
       " ('kickbacks', 0.7232261300086975),\n",
       " ('clambake', 0.722159206867218),\n",
       " ('feelings', 0.7113398313522339),\n",
       " ('hurt', 0.7056278586387634),\n",
       " ('stand', 0.700676679611206),\n",
       " ('romantically', 0.696991503238678),\n",
       " ('touch', 0.6966460943222046)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('trust') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ad166411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trusted', 0.49073344469070435),\n",
       " ('hurt', 0.4789045751094818),\n",
       " ('choose', 0.4549924433231354),\n",
       " ('ancients', 0.44181346893310547),\n",
       " ('protect', 0.4392508268356323),\n",
       " ('simple', 0.4251670837402344),\n",
       " ('responsibility', 0.42467594146728516),\n",
       " ('understand', 0.4231102764606476),\n",
       " ('responsible', 0.4229015111923218),\n",
       " ('honest', 0.417562872171402)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('trust') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b41ae46",
   "metadata": {},
   "source": [
    "**UNDERSTAND**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e63bce72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('understanding', 0.5034779906272888),\n",
       " ('know', 0.49283266067504883),\n",
       " ('satisfied', 0.4808705449104309),\n",
       " ('embarrassed', 0.4659891724586487),\n",
       " ('ignore', 0.46510598063468933),\n",
       " ('speak', 0.4632973372936249),\n",
       " ('responsible', 0.4619441032409668),\n",
       " ('dese', 0.4602375626564026),\n",
       " ('feelings', 0.4571031630039215),\n",
       " ('experience', 0.44959115982055664)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('understand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8b132cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('feelings', 0.7105677723884583),\n",
       " ('involved', 0.6907340884208679),\n",
       " ('personal', 0.6895884275436401),\n",
       " ('blame', 0.676398754119873),\n",
       " ('trust', 0.6755289435386658),\n",
       " ('reason', 0.6718007922172546),\n",
       " ('simply', 0.6631086468696594),\n",
       " ('paternal', 0.6341061592102051),\n",
       " ('shock', 0.6321044564247131),\n",
       " ('satisfaction', 0.632032573223114)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('understand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "066b6ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('interfere', 0.4792768359184265),\n",
       " ('badly', 0.47918057441711426),\n",
       " ('important', 0.47691741585731506),\n",
       " ('agree', 0.47026556730270386),\n",
       " ('mysticism', 0.46927690505981445),\n",
       " ('normal', 0.46905994415283203),\n",
       " ('respect', 0.46855005621910095),\n",
       " ('knowing', 0.4683611989021301),\n",
       " ('understanding', 0.45780640840530396),\n",
       " ('braincase', 0.4567636251449585)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('understand')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec45969",
   "metadata": {},
   "source": [
    "**TEAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "82225bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pilots', 0.5449494123458862),\n",
       " ('denominators', 0.528906524181366),\n",
       " ('hyped', 0.5192335247993469),\n",
       " ('football', 0.5163095593452454),\n",
       " ('olympics', 0.5132482647895813),\n",
       " ('route', 0.511203944683075),\n",
       " ('extraction', 0.5043143033981323),\n",
       " ('army', 0.5040054321289062),\n",
       " ('squad', 0.5011851787567139),\n",
       " ('shuttle', 0.4974614679813385)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('team')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "41d2674b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('debate', 0.8388311862945557),\n",
       " ('convenience', 0.790837287902832),\n",
       " ('football', 0.7882019877433777),\n",
       " ('plays', 0.7838284373283386),\n",
       " ('scottish', 0.7823089361190796),\n",
       " ('squares', 0.7816900014877319),\n",
       " ('magnet', 0.7784874439239502),\n",
       " ('consciousness', 0.7772064805030823),\n",
       " ('wealthiest', 0.7767531871795654),\n",
       " ('fund', 0.7757222652435303)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('team') # to note: debate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c0d885cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('route', 0.5844591856002808),\n",
       " ('location', 0.5833129286766052),\n",
       " ('pilots', 0.5521565079689026),\n",
       " ('deck', 0.5515555739402771),\n",
       " ('extraction', 0.5495181679725647),\n",
       " ('warp', 0.5445284843444824),\n",
       " ('season', 0.543950080871582),\n",
       " ('subsequently', 0.5432959198951721),\n",
       " ('goldfarb', 0.5430723428726196),\n",
       " ('noting', 0.5425517559051514)]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('team') # to note: quarterbacks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8198bae5",
   "metadata": {},
   "source": [
    "**COMMUNITY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7dbbbff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('schools', 0.6842179298400879),\n",
       " ('conceptual', 0.6549074053764343),\n",
       " ('founded', 0.6391774415969849),\n",
       " ('outreach', 0.6353266835212708),\n",
       " ('activities', 0.633095383644104),\n",
       " ('culture', 0.6302670836448669),\n",
       " ('troupe', 0.6292874813079834),\n",
       " ('artists', 0.6290776133537292),\n",
       " ('nation', 0.6234146356582642),\n",
       " ('diagnostician', 0.6204627752304077)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('community')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "faee719c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('leather', 0.9253839254379272),\n",
       " ('local', 0.9152456521987915),\n",
       " ('capitalist', 0.9124523401260376),\n",
       " ('helicopter', 0.9123915433883667),\n",
       " ('illegally', 0.9095520973205566),\n",
       " ('manufactures', 0.9091805815696716),\n",
       " ('consume', 0.90866619348526),\n",
       " ('nymphomania', 0.9077293276786804),\n",
       " ('factory', 0.9067306518554688),\n",
       " ('inspiration', 0.9064017534255981)]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('community')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "eb1ccf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('archive', 0.6628332138061523),\n",
       " ('conceptual', 0.6554428339004517),\n",
       " ('connections', 0.6542880535125732),\n",
       " ('mart', 0.6476332545280457),\n",
       " ('culture', 0.6476109027862549),\n",
       " ('subversive', 0.635859489440918),\n",
       " ('artists', 0.6339153051376343),\n",
       " ('intelligence', 0.6335156559944153),\n",
       " ('demolitions', 0.6262155175209045),\n",
       " ('ministry', 0.6237326264381409)]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('community') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eabf32",
   "metadata": {},
   "source": [
    "**SYSTEM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dbea1985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('systems', 0.7539252638816833),\n",
       " ('missile', 0.7466256022453308),\n",
       " ('energy', 0.72883141040802),\n",
       " ('radiation', 0.7135650515556335),\n",
       " ('nuclear', 0.7064035534858704),\n",
       " ('solar', 0.7037452459335327),\n",
       " ('source', 0.7006760239601135),\n",
       " ('engineering', 0.6996647715568542),\n",
       " ('communications', 0.6903157830238342),\n",
       " ('net', 0.6867450475692749)]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d7ee8294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aerospace', 0.9082595109939575),\n",
       " ('oswald', 0.9004662036895752),\n",
       " ('bronx', 0.8968282341957092),\n",
       " ('dna', 0.8957206606864929),\n",
       " ('outraged', 0.8950830101966858),\n",
       " ('fredericks', 0.8943237662315369),\n",
       " ('empire', 0.8921158313751221),\n",
       " ('emits', 0.8904328346252441),\n",
       " ('public', 0.8895198106765747),\n",
       " ('area', 0.88776695728302)]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a0340e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('source', 0.7663967609405518),\n",
       " ('nuclear', 0.7659327387809753),\n",
       " ('radiation', 0.7561413645744324),\n",
       " ('systems', 0.7542968392372131),\n",
       " ('trace', 0.7523331046104431),\n",
       " ('communications', 0.7447605133056641),\n",
       " ('area', 0.7443616986274719),\n",
       " ('warhead', 0.7371422052383423),\n",
       " ('solar', 0.7311319708824158),\n",
       " ('energy', 0.7268704771995544)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('system')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb08d2",
   "metadata": {},
   "source": [
    "#### 5.1.3 Exploring semantic contex of other related words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed992e1",
   "metadata": {},
   "source": [
    "**MAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "dde442c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.6054449677467346),\n",
       " ('lady', 0.549201250076294),\n",
       " ('foo', 0.548647940158844),\n",
       " ('masbath', 0.5018102526664734),\n",
       " ('energetic', 0.4894605278968811),\n",
       " ('rodger', 0.4733981490135193),\n",
       " ('ballplayers', 0.4708305597305298),\n",
       " ('oddness', 0.4707389175891876),\n",
       " ('fella', 0.46865832805633545),\n",
       " ('crone', 0.4650672674179077)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5a816978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.701050341129303),\n",
       " ('lady', 0.631764829158783),\n",
       " ('temples', 0.605690598487854),\n",
       " ('strapping', 0.5944605469703674),\n",
       " ('rodger', 0.5825244188308716),\n",
       " ('rounded', 0.5794467926025391),\n",
       " ('recap', 0.5785500407218933),\n",
       " ('ones', 0.5623739957809448),\n",
       " ('coeds', 0.5572714805603027),\n",
       " ('child', 0.5500539541244507)]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "580fabcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.5820141434669495),\n",
       " ('crone', 0.5408644080162048),\n",
       " ('foo', 0.5198589563369751),\n",
       " ('rodger', 0.491260290145874),\n",
       " ('oddness', 0.4738679528236389),\n",
       " ('masbath', 0.46986091136932373),\n",
       " ('lady', 0.46563705801963806),\n",
       " ('adage', 0.46172043681144714),\n",
       " ('rupture', 0.453797847032547),\n",
       " ('salivating', 0.44500553607940674)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('man')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8defd",
   "metadata": {},
   "source": [
    "**WOMAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e76820c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 0.6054449677467346),\n",
       " ('child', 0.5617663860321045),\n",
       " ('foo', 0.4981262683868408),\n",
       " ('lady', 0.4900900721549988),\n",
       " ('girl', 0.47887909412384033),\n",
       " ('creature', 0.47566017508506775),\n",
       " ('nonexistent', 0.4592101275920868),\n",
       " ('daughter', 0.45724567770957947),\n",
       " ('husband', 0.4571475684642792),\n",
       " ('schecter', 0.4443821907043457)]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8a942c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('child', 0.7411113381385803),\n",
       " ('age', 0.7117593288421631),\n",
       " ('temples', 0.7080915570259094),\n",
       " ('man', 0.7010504007339478),\n",
       " ('wife', 0.700002133846283),\n",
       " ('goober', 0.6919977068901062),\n",
       " ('career', 0.6721232533454895),\n",
       " ('fighting', 0.6719256043434143),\n",
       " ('dreams', 0.663955569267273),\n",
       " ('person', 0.6595151424407959)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f82e145c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('child', 0.5874792337417603),\n",
       " ('man', 0.5820141434669495),\n",
       " ('girl', 0.5248020887374878),\n",
       " ('glencorse', 0.5084810256958008),\n",
       " ('angel', 0.5066055655479431),\n",
       " ('hitler', 0.48588594794273376),\n",
       " ('foo', 0.48311787843704224),\n",
       " ('daughter', 0.4770365357398987),\n",
       " ('creature', 0.4752359688282013),\n",
       " ('lady', 0.469411700963974)]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5a0d29",
   "metadata": {},
   "source": [
    "**WORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "18394697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('job', 0.5232303142547607),\n",
       " ('working', 0.44977977871894836),\n",
       " ('oeuvre', 0.44652095437049866),\n",
       " ('worked', 0.38958531618118286),\n",
       " ('temperance', 0.3865731358528137),\n",
       " ('works', 0.3855735659599304),\n",
       " ('cutlery', 0.3799692392349243),\n",
       " ('endearingly', 0.3796161115169525),\n",
       " ('hard', 0.372171014547348),\n",
       " ('find', 0.3708341121673584)]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6dc2e50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mommies', 0.5877382159233093),\n",
       " ('heap', 0.5848551988601685),\n",
       " ('get', 0.582811713218689),\n",
       " ('pray', 0.5690260529518127),\n",
       " ('bumpkins', 0.5603040456771851),\n",
       " ('canvass', 0.5381692051887512),\n",
       " ('afford', 0.523683488368988),\n",
       " ('require', 0.5191129446029663),\n",
       " ('job', 0.5090126395225525),\n",
       " ('cruddy', 0.5080461502075195)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('work') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "961bbead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('job', 0.5411933660507202),\n",
       " ('working', 0.45024532079696655),\n",
       " ('worked', 0.447085440158844),\n",
       " ('hard', 0.3951362669467926),\n",
       " ('learn', 0.3840358257293701),\n",
       " ('postgraduate', 0.37969979643821716),\n",
       " ('build', 0.3776702284812927),\n",
       " ('handle', 0.3745790719985962),\n",
       " ('laredo', 0.36925578117370605),\n",
       " ('casino', 0.3681441843509674)]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('work') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e219d02",
   "metadata": {},
   "source": [
    "**PROFESSION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "630fe088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('legislated', 0.7628897428512573),\n",
       " ('subatomic', 0.7249383330345154),\n",
       " ('protocols', 0.7223734259605408),\n",
       " ('reman', 0.7152696847915649),\n",
       " ('implications', 0.7127866744995117),\n",
       " ('entrusted', 0.7122753858566284),\n",
       " ('expertise', 0.7090010643005371),\n",
       " ('primitive', 0.7086380124092102),\n",
       " ('creator', 0.7082618474960327),\n",
       " ('increased', 0.7080414295196533)]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('profession')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1281e712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('promotion', 0.8656356930732727),\n",
       " ('cave', 0.8507121205329895),\n",
       " ('cellulite', 0.8400963544845581),\n",
       " ('darn', 0.8358637094497681),\n",
       " ('claudia', 0.8341801762580872),\n",
       " ('sardine', 0.8266702890396118),\n",
       " ('cheyenne', 0.8249977231025696),\n",
       " ('peanuts', 0.8246921300888062),\n",
       " ('patient', 0.8220797181129456),\n",
       " ('kaminski', 0.8217106461524963)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_word('profession')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "96e3819e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('landscape', 0.743262529373169),\n",
       " ('scope', 0.7325222492218018),\n",
       " ('sultant', 0.7313746809959412),\n",
       " ('converting', 0.7279531359672546),\n",
       " ('undiplomatic', 0.7278914451599121),\n",
       " ('soran', 0.7275727987289429),\n",
       " ('grim', 0.7264983057975769),\n",
       " ('standby', 0.7250613570213318),\n",
       " ('rarefied', 0.7247754335403442),\n",
       " ('instructs', 0.723965048789978)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_word('profession')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655d5d5c",
   "metadata": {},
   "source": [
    "#### 5.1.4  Using the specialized models to compare the shift of specific words relations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e8c2d3",
   "metadata": {},
   "source": [
    "**SIMILARITY**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f33c289",
   "metadata": {},
   "source": [
    "**MAN and WOMAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "68f20bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60544497"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('man', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d52ed1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7010504"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similarity('man', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4094bfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5820142"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similarity('man', 'woman')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a8ee54",
   "metadata": {},
   "source": [
    "**WOMAN and GOVERNMENT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d8fdb946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03935369"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('woman', 'government')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2c7cb6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42209566"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similarity('woman', 'government')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "af2e4b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0048919395"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similarity('woman', 'government')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1528c8b6",
   "metadata": {},
   "source": [
    "**MAN and GOVERNMENT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "91cf84bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07227807"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('man', 'government')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f6d397a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26944447"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similarity('man', 'government')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "75d44a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08255575"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similarity('man', 'government')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d058bec7",
   "metadata": {},
   "source": [
    "**'community' and 'leadership'** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1b114fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7943674"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similarity('community', 'leadership')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8af2539a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32791895"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similarity('community', 'leadership')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc0846",
   "metadata": {},
   "source": [
    "**'decision' and 'burden'** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "11467df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63971066"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similarity('decision', 'burden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f0c643d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23350218"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similarity('decision', 'burden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05864f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de95daad",
   "metadata": {},
   "source": [
    "#### 5.1.5  Using the specialized models to compare the shift of specific words analogies among words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47803d",
   "metadata": {},
   "source": [
    "(WOMAN + DECISION) - COMMUNITY \n",
    "here I'm trying to reach a semantic area where the meaning of woman is closer to that of decision(agentic content) and not to that of community(communal content)and see which words have the highest rate of similarity within the three models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ece213b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('choice', 0.6356691718101501),\n",
       " ('child', 0.6329909563064575),\n",
       " ('sense', 0.6222999095916748),\n",
       " ('pappa', 0.6048707365989685),\n",
       " ('laugh', 0.5949430465698242),\n",
       " ('aristocrat', 0.5930051207542419),\n",
       " ('person', 0.5819121599197388),\n",
       " ('difference', 0.5758541226387024),\n",
       " ('commoned', 0.5652105808258057),\n",
       " ('anomaly', 0.5626065135002136)]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.most_similar(positive=['woman','decision'], negative=['community'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4dc56f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mistake', 0.48911574482917786),\n",
       " ('whether', 0.4799969792366028),\n",
       " ('soulmates', 0.4714689254760742),\n",
       " ('pleez', 0.42591392993927),\n",
       " ('fool', 0.417987197637558),\n",
       " ('accusations', 0.4094550609588623),\n",
       " ('difference', 0.4024757742881775),\n",
       " ('happy', 0.4006378650665283),\n",
       " ('piracy', 0.3965551257133484),\n",
       " ('moment', 0.39601054787635803)]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.most_similar(positive=['woman','decision'], negative=['community'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e6289cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fool', 0.41892388463020325),\n",
       " ('mistake', 0.41443073749542236),\n",
       " ('choice', 0.4090973138809204),\n",
       " ('psychologically', 0.40358176827430725),\n",
       " ('airstream', 0.4016519784927368),\n",
       " ('aufstehen', 0.3994062542915344),\n",
       " ('comical', 0.3988175392150879),\n",
       " ('moment', 0.39605751633644104),\n",
       " ('batman', 0.3784945607185364),\n",
       " ('statement', 0.3745868504047394)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['woman','decision'], negative=['community'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2d0c1f",
   "metadata": {},
   "source": [
    "(MAN + COMMUNITY) - DECISION here, on the contraty, I'm trying to reach a semantic area where the meaning of man is closer to that of community(communal content) and not to that of decision(agentic content)and see which words have the highest rate of similarity within the three models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "fd5af624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nannies', 0.4896811544895172),\n",
       " ('nigger', 0.47785836458206177),\n",
       " ('carnuba', 0.47541964054107666),\n",
       " ('houses', 0.4685822129249573),\n",
       " ('conceptual', 0.46659553050994873),\n",
       " ('filthy', 0.45753687620162964),\n",
       " ('bitches', 0.45481887459754944),\n",
       " ('cattle', 0.45403164625167847),\n",
       " ('outreach', 0.4502005875110626),\n",
       " ('wax', 0.4475507438182831)]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['man','community'], negative=['decision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "04b1fd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lunching', 0.6347359418869019),\n",
       " ('named', 0.6292093992233276),\n",
       " ('globe', 0.6284742951393127),\n",
       " ('colt', 0.6126193404197693),\n",
       " ('paging', 0.6103739738464355),\n",
       " ('young', 0.6041408181190491),\n",
       " ('ralston', 0.6033040285110474),\n",
       " ('doubler', 0.6025220155715942),\n",
       " ('chico', 0.5978190302848816),\n",
       " ('duluth', 0.595352828502655)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.most_similar(positive=['man','community'], negative=['decision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a572a863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pakistanis', 0.45795613527297974),\n",
       " ('indian', 0.45714566111564636),\n",
       " ('halfsies', 0.4443908929824829),\n",
       " ('loam', 0.4421478807926178),\n",
       " ('white', 0.4413589537143707),\n",
       " ('ties', 0.44014933705329895),\n",
       " ('czaristic', 0.43322309851646423),\n",
       " ('butchered', 0.4332199990749359),\n",
       " ('windshields', 0.42714884877204895),\n",
       " ('alps', 0.4269218146800995)]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.most_similar(positive=['man','community'], negative=['decision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec933b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f0ff322",
   "metadata": {},
   "source": [
    "#### 5.1.6 Using the specialized models to compare the shift on semantic mean among words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691247e4",
   "metadata": {},
   "source": [
    "**SEMANTIC MEAN** #still working on this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b08e10",
   "metadata": {},
   "source": [
    "**on ['people', 'community','trust', 'reliance']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "df96ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['people', 'community','trust', 'reliance']\n",
    "p = np.array([model.wv.get_vector(w) for w in words]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "31a8c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = p.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "fb7395ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('people', 0.8543640375137329),\n",
       " ('trust', 0.5830052495002747),\n",
       " ('ways', 0.5410557389259338),\n",
       " ('superheroes', 0.5144560933113098),\n",
       " ('community', 0.5004802942276001),\n",
       " ('enemies', 0.4997462034225464),\n",
       " ('others', 0.49300453066825867),\n",
       " ('experience', 0.4922106862068176),\n",
       " ('friends', 0.49151352047920227),\n",
       " ('enslaved', 0.4892796576023102)]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3a7e1212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hewlitt', 0.36934706568717957),\n",
       " ('tribune', 0.34659940004348755),\n",
       " ('kidnappings', 0.333657830953598),\n",
       " ('violinist', 0.3323066234588623),\n",
       " ('seller', 0.33013594150543213),\n",
       " ('bloodletting', 0.32978400588035583),\n",
       " ('ramp', 0.32758015394210815),\n",
       " ('designing', 0.3249436020851135),\n",
       " ('denny', 0.3240055441856384),\n",
       " ('barroom', 0.32174018025398254)]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "11a274cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('logos', 0.3901382386684418),\n",
       " ('crumples', 0.3677961528301239),\n",
       " ('lawson', 0.34882211685180664),\n",
       " ('nein', 0.33804768323898315),\n",
       " ('mask', 0.33234742283821106),\n",
       " ('spontaneously', 0.331522673368454),\n",
       " ('slicer', 0.3285239636898041),\n",
       " ('theatre', 0.32038724422454834),\n",
       " ('community', 0.3179462254047394),\n",
       " ('heisman', 0.31440597772598267)]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be639fe",
   "metadata": {},
   "source": [
    "**on ['people', 'assertive','decision', 'leader']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f9865dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['people', 'assertive','decision', 'leader']\n",
    "p = np.array([model.wv.get_vector(w) for w in words]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7ae53eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = p.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "53b26615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('people', 0.8573208451271057),\n",
       " ('enemies', 0.6085239052772522),\n",
       " ('others', 0.5631603002548218),\n",
       " ('decisions', 0.5538720488548279),\n",
       " ('humans', 0.5350243449211121),\n",
       " ('men', 0.5336982011795044),\n",
       " ('satisfy', 0.5143131613731384),\n",
       " ('choices', 0.5132899284362793),\n",
       " ('minds', 0.5125402212142944),\n",
       " ('subtitles', 0.5106819868087769)]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7427f0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('transplanted', 0.40979987382888794),\n",
       " ('violinist', 0.39339694380760193),\n",
       " ('sleeps', 0.3581490218639374),\n",
       " ('barroom', 0.354207843542099),\n",
       " ('puppeteer', 0.33356913924217224),\n",
       " ('giggled', 0.33277732133865356),\n",
       " ('insect', 0.3327294886112213),\n",
       " ('motherhood', 0.3317810595035553),\n",
       " ('res', 0.3293803334236145),\n",
       " ('courtesy', 0.3291054964065552)]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "79ecbc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('heisman', 0.41353851556777954),\n",
       " ('lawson', 0.39070722460746765),\n",
       " ('copley', 0.3617148697376251),\n",
       " ('millenium', 0.35219815373420715),\n",
       " ('nein', 0.35097578167915344),\n",
       " ('vets', 0.338616281747818),\n",
       " ('icom', 0.3380037248134613),\n",
       " ('mold', 0.3375433087348938),\n",
       " ('sidelines', 0.3365720808506012),\n",
       " ('gaslights', 0.3347738981246948)]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ed1dcd",
   "metadata": {},
   "source": [
    "**on ['people', 'assertive','decision', 'leadership']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5a074441",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['people', 'assertive','decision', 'leadership']\n",
    "p = np.array([model.wv.get_vector(w) for w in words]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "75f5dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = p.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9f2f4563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('people', 0.8909914493560791),\n",
       " ('others', 0.5521984696388245),\n",
       " ('enemies', 0.5449724197387695),\n",
       " ('decisions', 0.532958984375),\n",
       " ('choices', 0.517030656337738),\n",
       " ('mistakes', 0.495879203081131),\n",
       " ('ways', 0.4954264760017395),\n",
       " ('humans', 0.49180448055267334),\n",
       " ('subtitles', 0.4896656572818756),\n",
       " ('men', 0.4819871783256531)]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "35b0acb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('transplanted', 0.38021594285964966),\n",
       " ('violinist', 0.37549614906311035),\n",
       " ('barroom', 0.3300454616546631),\n",
       " ('jerusalem', 0.32677099108695984),\n",
       " ('giggled', 0.32364723086357117),\n",
       " ('puppeteer', 0.31323134899139404),\n",
       " ('guy', 0.3124004602432251),\n",
       " ('sleeps', 0.31091198325157166),\n",
       " ('artichoke', 0.3103811740875244),\n",
       " ('denny', 0.30968597531318665)]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "688d15dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('heisman', 0.37713614106178284),\n",
       " ('lawson', 0.36850711703300476),\n",
       " ('sidelines', 0.3394820988178253),\n",
       " ('copley', 0.3336664140224457),\n",
       " ('liebkind', 0.3256796896457672),\n",
       " ('logos', 0.3252268135547638),\n",
       " ('celebrities', 0.32054105401039124),\n",
       " ('millenium', 0.3189670741558075),\n",
       " ('vets', 0.3184655010700226),\n",
       " ('icom', 0.31364715099334717)]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe8eb2d",
   "metadata": {},
   "source": [
    "**on ['man', 'assertive','decision', 'leadership']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "cc229415",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['man', 'assertive','decision', 'leadership']\n",
    "p = np.array([model.wv.get_vector(w) for w in words]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "89f98c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = p.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "bc304183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 0.8379746079444885),\n",
       " ('compromises', 0.5378971695899963),\n",
       " ('woman', 0.5346940755844116),\n",
       " ('middleman', 0.5294601321220398),\n",
       " ('warrior', 0.508126974105835),\n",
       " ('crone', 0.4970970153808594),\n",
       " ('energetic', 0.49622389674186707),\n",
       " ('watchmaker', 0.49425026774406433),\n",
       " ('christendom', 0.4940127730369568),\n",
       " ('lady', 0.49303022027015686)]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "99039879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cotillions', 0.45137643814086914),\n",
       " ('traffickers', 0.4396498501300812),\n",
       " ('fags', 0.43946096301078796),\n",
       " ('tasted', 0.42783647775650024),\n",
       " ('invalid', 0.4232669174671173),\n",
       " ('embalming', 0.4225144386291504),\n",
       " ('impulsive', 0.4194503128528595),\n",
       " ('lumped', 0.41651809215545654),\n",
       " ('hoboes', 0.4164566993713379),\n",
       " ('sentiments', 0.4093283414840698)]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "1f932eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('violated', 0.4078415036201477),\n",
       " ('relocated', 0.39880913496017456),\n",
       " ('stages', 0.39285793900489807),\n",
       " ('inning', 0.39022254943847656),\n",
       " ('lasts', 0.38542482256889343),\n",
       " ('felon', 0.3852330446243286),\n",
       " ('televisions', 0.3802381753921509),\n",
       " ('bunker', 0.37743017077445984),\n",
       " ('communities', 0.3759319484233856),\n",
       " ('suggestive', 0.3751503527164459)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d2176",
   "metadata": {},
   "source": [
    "**on ['woman', 'assertive','decision', 'leadership']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a047d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['woman', 'assertive','decision', 'leadership']\n",
    "p = np.array([model.wv.get_vector(w) for w in words]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c6c0bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = p.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0bbc2b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.8745322227478027),\n",
       " ('creature', 0.5308802723884583),\n",
       " ('piracy', 0.50499427318573),\n",
       " ('decision', 0.5037699937820435),\n",
       " ('child', 0.49961674213409424),\n",
       " ('lover', 0.4979061484336853),\n",
       " ('man', 0.4960494637489319),\n",
       " ('human', 0.4930232763290405),\n",
       " ('psychologically', 0.491053968667984),\n",
       " ('guilderians', 0.4861159324645996)]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "264508cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stirred', 0.4512596130371094),\n",
       " ('presscorp', 0.42348575592041016),\n",
       " ('shaken', 0.4112589955329895),\n",
       " ('foot', 0.4100252091884613),\n",
       " ('siphoned', 0.4078614115715027),\n",
       " ('troublesome', 0.40690886974334717),\n",
       " ('sentiments', 0.39803823828697205),\n",
       " ('loudly', 0.397384375333786),\n",
       " ('beatles', 0.3954726755619049),\n",
       " ('psycho', 0.3924340307712555)]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "22050901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('oriental', 0.47087058424949646),\n",
       " ('file', 0.4466172158718109),\n",
       " ('batteries', 0.43222734332084656),\n",
       " ('scoop', 0.4185521900653839),\n",
       " ('recorded', 0.412338525056839),\n",
       " ('meigs', 0.4075089991092682),\n",
       " ('previsualized', 0.40516507625579834),\n",
       " ('coquette', 0.4020298421382904),\n",
       " ('added', 0.4001396596431732),\n",
       " ('century', 0.39962536096572876)]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce4dad4",
   "metadata": {},
   "source": [
    "**on ['man', 'community','trust', 'reliance']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "efe9b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['man', 'community','trust', 'reliance']\n",
    "p = np.array([model.wv.get_vector(w) for w in words]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c34a21e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = p.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e0279223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 0.7718935012817383),\n",
       " ('trust', 0.6279093027114868),\n",
       " ('trusted', 0.5385328531265259),\n",
       " ('woman', 0.5130258798599243),\n",
       " ('incontinent', 0.5054967999458313),\n",
       " ('embrace', 0.4877853989601135),\n",
       " ('implicitly', 0.48108041286468506),\n",
       " ('warrior', 0.4807596504688263),\n",
       " ('loyalty', 0.4699474573135376),\n",
       " ('idealism', 0.46759843826293945)]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "37058dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('carel', 0.483841210603714),\n",
       " ('taking', 0.4676298201084137),\n",
       " ('sleeves', 0.4489387273788452),\n",
       " ('kidnappings', 0.4431841969490051),\n",
       " ('takes', 0.4425192177295685),\n",
       " ('unconfirmed', 0.4388817846775055),\n",
       " ('fags', 0.43847358226776123),\n",
       " ('designing', 0.4312494695186615),\n",
       " ('beatles', 0.42839154601097107),\n",
       " ('cleans', 0.4235756993293762)]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "05dfa06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jongg', 0.39242836833000183),\n",
       " ('bulgarian', 0.38055333495140076),\n",
       " ('theatre', 0.3805515170097351),\n",
       " ('addict', 0.37881410121917725),\n",
       " ('sparerib', 0.3733268976211548),\n",
       " ('undetected', 0.37021321058273315),\n",
       " ('propagandized', 0.3671320676803589),\n",
       " ('cheaters', 0.35967281460762024),\n",
       " ('perversions', 0.3563160300254822),\n",
       " ('rumble', 0.35456255078315735)]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5a0584",
   "metadata": {},
   "source": [
    "**on ['woman', 'community','trust', 'reliance']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "00060566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 0.7718935012817383),\n",
       " ('trust', 0.6279093027114868),\n",
       " ('trusted', 0.5385328531265259),\n",
       " ('woman', 0.5130258798599243),\n",
       " ('incontinent', 0.5054967999458313),\n",
       " ('embrace', 0.4877853989601135),\n",
       " ('implicitly', 0.48108041286468506),\n",
       " ('warrior', 0.4807596504688263),\n",
       " ('loyalty', 0.4699474573135376),\n",
       " ('idealism', 0.46759843826293945)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['woman', 'community','trust', 'reliance']\n",
    "model.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3b5fb0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = p.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "465befd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 0.7718935012817383),\n",
       " ('trust', 0.6279093027114868),\n",
       " ('trusted', 0.5385328531265259),\n",
       " ('woman', 0.5130258798599243),\n",
       " ('incontinent', 0.5054967999458313),\n",
       " ('embrace', 0.4877853989601135),\n",
       " ('implicitly', 0.48108041286468506),\n",
       " ('warrior', 0.4807596504688263),\n",
       " ('loyalty', 0.4699474573135376),\n",
       " ('idealism', 0.46759843826293945)]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e21427c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('carel', 0.483841210603714),\n",
       " ('taking', 0.4676298201084137),\n",
       " ('sleeves', 0.4489387273788452),\n",
       " ('kidnappings', 0.4431841969490051),\n",
       " ('takes', 0.4425192177295685),\n",
       " ('unconfirmed', 0.4388817846775055),\n",
       " ('fags', 0.43847358226776123),\n",
       " ('designing', 0.4312494695186615),\n",
       " ('beatles', 0.42839154601097107),\n",
       " ('cleans', 0.4235756993293762)]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leia.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "54a7b57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jongg', 0.39242836833000183),\n",
       " ('bulgarian', 0.38055333495140076),\n",
       " ('theatre', 0.3805515170097351),\n",
       " ('addict', 0.37881410121917725),\n",
       " ('sparerib', 0.3733268976211548),\n",
       " ('undetected', 0.37021321058273315),\n",
       " ('propagandized', 0.3671320676803589),\n",
       " ('cheaters', 0.35967281460762024),\n",
       " ('perversions', 0.3563160300254822),\n",
       " ('rumble', 0.35456255078315735)]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luke.wv.similar_by_vector(mv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ddcd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54a345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab58f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
